{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "## Car Price Prediction\n",
    "\n",
    "Predict if the price of a car is low or high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/dataTrain_carListings.zip')\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Mileage', 'M_Camry', 'M_Camry4dr', 'M_CamryBase', 'M_CamryL',\n",
       "       'M_CamryLE', 'M_CamrySE', 'M_CamryXLE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.1\n",
    "\n",
    "Estimate a Decision Tree Classifier Manually using the code created in the Notebook #13\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables iniciales\n",
    "max_depth = None        # Profundidad\n",
    "num_pct = 10            # Número de percentiles\n",
    "max_features = None     # Variables máximas\n",
    "min_gain=0.001          # Mínima ganancia\n",
    "j = 1                   # Variable 1, calculate posible splitting points\n",
    "k = 3                   # Partir datos a partir de la partición 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particiones por percentiles\n",
    "splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para particiones únicas\n",
    "splits = np.unique(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_l = X.iloc[:, j] < splits[k]   # Toma todos los elementos en que j (millaje) < k (split #3)\n",
    "y_l = y.loc[filter_l]                 # Toma elementos True de filter_l\n",
    "y_r = y.loc[~filter_l]                # Toma elementos False de filter_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini impurity -> probabilidad de que la muestra escogida en un nodo sea nombrada mal, por la ditribución de la muestra.\n",
    "\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10711336645671388, 0.48835136419789327)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_l = gini(y_l)         # Gini de partición izquierda\n",
    "gini_r = gini(y_r)         # Gini de partición derecha\n",
    "\n",
    "gini_l, gini_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(X_col, y, split):\n",
    "    \"Calculate the gain of an split k on feature j\"\n",
    "    \n",
    "    filter_l = X_col < split                     # Toma todos los elementos en que j (millaje) < k (split #3)\n",
    "    y_l = y.loc[filter_l]                        # Toma elementos True de filter_l -> y_izq\n",
    "    y_r = y.loc[~filter_l]                       # Toma elementos False de filter_l -> y_der\n",
    "    \n",
    "    n_l = y_l.shape[0]                           # Número de elementos en y_l\n",
    "    n_r = y_r.shape[0]                           # Número de elementos en y_r\n",
    "    \n",
    "    # Cálculo de coeficiente de Gini para cada y (high_price)\n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r) \n",
    "    #ganancia media , menos la suma ponderada de y derecho y del y izquierdo.\n",
    "    # Si no pondero podría tener una partición que me envíe solo un dato\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11336562635752745"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gini impurity de: [columna j de X (millaje), y (high_price), k (split #3)]\n",
    "gini_impurity(X.iloc[:, j], y, splits[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        #busco todos los j para hallar todos los posibles splits y luego hago la prueba para cada uno de ellos\n",
    "        \n",
    "        \n",
    "        # For all splits\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2014.0, 0.23223870086324505)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j, split, gain = best_split(X, y, 5) #indice, particion y ganancia\n",
    "j, split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_l = X.iloc[:, j] < split\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 4169, 8981)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0], y_l.shape[0], y_r.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5795437262357415, 0.07939553849844087, 0.8117136176372342)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(), y_l.mean(), y_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10): #\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain) #gain=-1\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "    # tree['gain'] = gain\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5795316301703163,\n",
       " 'level': 0,\n",
       " 'split': [1, 51704.54545454545],\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23348567756020572,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8377538829151733,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 8368,\n",
       "  'gain': 0.0359166442135464},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12771739130434784,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 4782,\n",
       "  'gain': 0.04846022210319853}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=1, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5795316301703163,\n",
       " 'level': 0,\n",
       " 'split': [1, 51704.54545454545],\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23348567756020572,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8377538829151733,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 8368,\n",
       "  'gain': 0.0359166442135464,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.3403880070546737,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 565,\n",
       "   'gain': 0.06001982703810749,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.058823529411764705,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 151,\n",
       "    'gain': 0.005661757290357922},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.44471153846153844,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 414,\n",
       "    'gain': 0.030742158715547196}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 0.8737988468930173,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 7803,\n",
       "   'gain': 0.015250286354762527,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 0.731399157697707,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 2135,\n",
       "    'gain': 0.026428677839232695},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.927336860670194,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 5668,\n",
       "    'gain': 0.00819701541689713}}},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12771739130434784,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 4782,\n",
       "  'gain': 0.04846022210319853,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.03882418191902385,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 3604,\n",
       "   'gain': 0.00487662145694924,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.006722024515618822,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 2527,\n",
       "    'gain': 5.4441857069140176e-05},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.11492122335495829,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1077,\n",
       "    'gain': 0.010886522292940848}},\n",
       "  'sr': {'y_pred': 0,\n",
       "   'y_prob': 0.4,\n",
       "   'level': 2,\n",
       "   'split': [1, 73157.0],\n",
       "   'n_samples': 1178,\n",
       "   'gain': 0.039461121020537004,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.486013986013986,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 856,\n",
       "    'gain': 0.02508095551456313},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.1728395061728395,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 322,\n",
       "    'gain': 0.014901907350238275}}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = tree_grow(X, y, level=0, min_gain=0.001, max_depth=3, num_pct=10)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False): #X es X_test\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.2\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers Manually using the code created in the Notebook #13\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10): #\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain) #gain=-1\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "        \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "    # tree['gain'] = gain\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5795316301703163,\n",
       " 'level': 0,\n",
       " 'split': [1, 51704.54545454545],\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23348567756020572,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8377538829151733,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 8368,\n",
       "  'gain': 0.0359166442135464},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12771739130434784,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 4782,\n",
       "  'gain': 0.04846022210319853}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=1, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5795316301703163,\n",
       " 'level': 0,\n",
       " 'split': [1, 51704.54545454545],\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23348567756020572,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8377538829151733,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 8368,\n",
       "  'gain': 0.0359166442135464,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.3403880070546737,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 565,\n",
       "   'gain': 0.06001982703810749,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.058823529411764705,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 151,\n",
       "    'gain': 0.005661757290357922},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.44471153846153844,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 414,\n",
       "    'gain': 0.030742158715547196}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 0.8737988468930173,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 7803,\n",
       "   'gain': 0.015250286354762527,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 0.731399157697707,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 2135,\n",
       "    'gain': 0.026428677839232695},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.927336860670194,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 5668,\n",
       "    'gain': 0.00819701541689713}}},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12771739130434784,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 4782,\n",
       "  'gain': 0.04846022210319853,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.03882418191902385,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 3604,\n",
       "   'gain': 0.00487662145694924,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.006722024515618822,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 2527,\n",
       "    'gain': 5.4441857069140176e-05},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.11492122335495829,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1077,\n",
       "    'gain': 0.010886522292940848}},\n",
       "  'sr': {'y_pred': 0,\n",
       "   'y_prob': 0.4,\n",
       "   'level': 2,\n",
       "   'split': [1, 73157.0],\n",
       "   'n_samples': 1178,\n",
       "   'gain': 0.039461121020537004,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.486013986013986,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 856,\n",
       "    'gain': 0.02508095551456313},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.1728395061728395,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 322,\n",
       "    'gain': 0.014901907350238275}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = tree_grow(X, y, level=0, min_gain=0.001, max_depth=3, num_pct=10)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False): #X es X_test\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15         True\n",
       "47         True\n",
       "85        False\n",
       "141        True\n",
       "226        True\n",
       "244        True\n",
       "258        True\n",
       "333       False\n",
       "366        True\n",
       "452        True\n",
       "453        True\n",
       "466        True\n",
       "478        True\n",
       "514        True\n",
       "562        True\n",
       "691        True\n",
       "739        True\n",
       "767        True\n",
       "825        True\n",
       "874        True\n",
       "1033       True\n",
       "1055       True\n",
       "1074       True\n",
       "1102       True\n",
       "1176       True\n",
       "1200       True\n",
       "1231       True\n",
       "1259       True\n",
       "1347       True\n",
       "1377       True\n",
       "          ...  \n",
       "498852     True\n",
       "498870     True\n",
       "498896     True\n",
       "498974     True\n",
       "498995     True\n",
       "499014     True\n",
       "499033     True\n",
       "499139     True\n",
       "499206     True\n",
       "499265     True\n",
       "499320     True\n",
       "499338     True\n",
       "499371    False\n",
       "499416    False\n",
       "499422     True\n",
       "499442     True\n",
       "499461     True\n",
       "499478     True\n",
       "499496     True\n",
       "499554     True\n",
       "499560     True\n",
       "499577     True\n",
       "499629     True\n",
       "499729     True\n",
       "499754     True\n",
       "499785     True\n",
       "499889     True\n",
       "499937     True\n",
       "499971     True\n",
       "499991     True\n",
       "Name: HighPrice, Length: 13150, dtype: bool"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_predict(X, tree) == y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.3\n",
    "\n",
    "Implement the variable max_features on the Decision Tree Classifier created in 11.1.\n",
    "\n",
    "Compare the impact in the results by varing the parameter max_features\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aparrado\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-dbe3efe598d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0maccuracy_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# list of values to try for max_features\n",
    "feature_range = range(1, len(\"HighPrice\")+1)\n",
    "\n",
    "# list to store the average Accuracy for each value of max_features\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 10-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "for feature in feature_range:\n",
    "    clf = DecisionTreeClassifier(max_features=feature, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(feature_range, accuracy_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.4\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers with `max_features = log(n_features)`\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.5\n",
    "\n",
    "Using sklearn, train a RandomForestClassifier\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.6\n",
    "\n",
    "Find the best parameters of the RandomForestClassifier (max_depth, max_features, n_estimators)\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
